{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4086e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:21:28.017198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-16 11:21:28.017297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-16 11:21:28.018413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-16 11:21:28.023609: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-16 11:21:28.698177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# para no usar GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7593fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  9 of 9 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# lista de acciones y precio de petroleo y oro\n",
    "tickers = ['GOOG', 'AMZN', 'META', 'TSLA', 'AAPL', 'MSFT', 'NVDA', 'CL=F', 'GC=F']\n",
    "data = yf.download(tickers, start='2010-01-01', end='2024-12-31', auto_adjust=False)['Adj Close']\n",
    "data = data.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ab436f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>CL=F</th>\n",
       "      <th>GC=F</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>6.431897</td>\n",
       "      <td>6.695000</td>\n",
       "      <td>81.510002</td>\n",
       "      <td>1117.699951</td>\n",
       "      <td>15.536651</td>\n",
       "      <td>38.050671</td>\n",
       "      <td>23.211447</td>\n",
       "      <td>0.423884</td>\n",
       "      <td>1.592667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>6.443018</td>\n",
       "      <td>6.734500</td>\n",
       "      <td>81.769997</td>\n",
       "      <td>1118.099976</td>\n",
       "      <td>15.468233</td>\n",
       "      <td>38.050671</td>\n",
       "      <td>23.218939</td>\n",
       "      <td>0.430073</td>\n",
       "      <td>1.592667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>6.340532</td>\n",
       "      <td>6.612500</td>\n",
       "      <td>83.180000</td>\n",
       "      <td>1135.900024</td>\n",
       "      <td>15.078297</td>\n",
       "      <td>38.050671</td>\n",
       "      <td>23.076441</td>\n",
       "      <td>0.432824</td>\n",
       "      <td>1.592667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>6.328812</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>82.660004</td>\n",
       "      <td>1133.099976</td>\n",
       "      <td>14.727283</td>\n",
       "      <td>38.050671</td>\n",
       "      <td>22.836458</td>\n",
       "      <td>0.424342</td>\n",
       "      <td>1.592667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>6.370886</td>\n",
       "      <td>6.676000</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>1138.199951</td>\n",
       "      <td>14.923613</td>\n",
       "      <td>38.050671</td>\n",
       "      <td>22.993948</td>\n",
       "      <td>0.425259</td>\n",
       "      <td>1.592667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>254.655716</td>\n",
       "      <td>225.059998</td>\n",
       "      <td>69.239998</td>\n",
       "      <td>2612.300049</td>\n",
       "      <td>195.766968</td>\n",
       "      <td>599.316772</td>\n",
       "      <td>433.583038</td>\n",
       "      <td>139.657150</td>\n",
       "      <td>430.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>257.578674</td>\n",
       "      <td>229.050003</td>\n",
       "      <td>70.099998</td>\n",
       "      <td>2620.000000</td>\n",
       "      <td>197.345184</td>\n",
       "      <td>607.209778</td>\n",
       "      <td>437.647369</td>\n",
       "      <td>140.207108</td>\n",
       "      <td>462.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>258.396667</td>\n",
       "      <td>227.050003</td>\n",
       "      <td>69.620003</td>\n",
       "      <td>2638.800049</td>\n",
       "      <td>196.875717</td>\n",
       "      <td>602.813660</td>\n",
       "      <td>436.432068</td>\n",
       "      <td>139.917130</td>\n",
       "      <td>454.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>254.974930</td>\n",
       "      <td>223.750000</td>\n",
       "      <td>70.599998</td>\n",
       "      <td>2617.199951</td>\n",
       "      <td>193.819183</td>\n",
       "      <td>599.276855</td>\n",
       "      <td>428.881104</td>\n",
       "      <td>136.997391</td>\n",
       "      <td>431.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>251.593079</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>70.989998</td>\n",
       "      <td>2606.100098</td>\n",
       "      <td>192.470734</td>\n",
       "      <td>590.714417</td>\n",
       "      <td>423.202911</td>\n",
       "      <td>137.477356</td>\n",
       "      <td>417.410004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3773 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            AAPL        AMZN       CL=F         GC=F        GOOG  \\\n",
       "Date                                                                     \n",
       "2010-01-04    6.431897    6.695000  81.510002  1117.699951   15.536651   \n",
       "2010-01-05    6.443018    6.734500  81.769997  1118.099976   15.468233   \n",
       "2010-01-06    6.340532    6.612500  83.180000  1135.900024   15.078297   \n",
       "2010-01-07    6.328812    6.500000  82.660004  1133.099976   14.727283   \n",
       "2010-01-08    6.370886    6.676000  82.750000  1138.199951   14.923613   \n",
       "...                ...         ...        ...          ...         ...   \n",
       "2024-12-23  254.655716  225.059998  69.239998  2612.300049  195.766968   \n",
       "2024-12-24  257.578674  229.050003  70.099998  2620.000000  197.345184   \n",
       "2024-12-26  258.396667  227.050003  69.620003  2638.800049  196.875717   \n",
       "2024-12-27  254.974930  223.750000  70.599998  2617.199951  193.819183   \n",
       "2024-12-30  251.593079  221.300003  70.989998  2606.100098  192.470734   \n",
       "\n",
       "Ticker            META        MSFT        NVDA        TSLA  \n",
       "Date                                                        \n",
       "2010-01-04   38.050671   23.211447    0.423884    1.592667  \n",
       "2010-01-05   38.050671   23.218939    0.430073    1.592667  \n",
       "2010-01-06   38.050671   23.076441    0.432824    1.592667  \n",
       "2010-01-07   38.050671   22.836458    0.424342    1.592667  \n",
       "2010-01-08   38.050671   22.993948    0.425259    1.592667  \n",
       "...                ...         ...         ...         ...  \n",
       "2024-12-23  599.316772  433.583038  139.657150  430.600006  \n",
       "2024-12-24  607.209778  437.647369  140.207108  462.279999  \n",
       "2024-12-26  602.813660  436.432068  139.917130  454.130005  \n",
       "2024-12-27  599.276855  428.881104  136.997391  431.660004  \n",
       "2024-12-30  590.714417  423.202911  137.477356  417.410004  \n",
       "\n",
       "[3773 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6453f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(data, window_size=101, max_samples=3000):\n",
    "    series = []\n",
    "    for i in range(0, len(data)-window_size+1, 1):\n",
    "        window = data.iloc[i:i+window_size].T\n",
    "        series.append(window.values)\n",
    "        if len(series) == max_samples:\n",
    "            break\n",
    "    return np.array(series)\n",
    "\n",
    "def inject_random_nans(X, nan_ratio=0.05, seed=42):\n",
    "    \"\"\"\n",
    "    Inserta NaNs aleatoriamente en un porcentaje de los datos en X.\n",
    "    nan_ratio: proporciÃ³n de valores que serÃ¡n convertidos a NaN (e.g., 0.05 = 5%)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    X_nans = X.copy()\n",
    "    num_samples, num_series, time_steps = X_nans.shape\n",
    "    total_values = num_samples * num_series * time_steps\n",
    "    num_nans = int(nan_ratio * total_values)\n",
    "\n",
    "    # Seleccionar Ã­ndices planos para asignar NaNs\n",
    "    flat_indices = np.random.choice(total_values, num_nans, replace=False)\n",
    "\n",
    "    # Convertir Ã­ndices planos a 3D\n",
    "    sample_idx, series_idx, time_idx = np.unravel_index(flat_indices, X_nans.shape)\n",
    "    X_nans[sample_idx, series_idx, time_idx] = np.nan\n",
    "\n",
    "    return X_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e0c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preparados:\n",
      "X shape: (3000, 9, 100)\n",
      "Y shape: (3000, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "# escalamiento de datos para que estÃ©n entre 0 y 1\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, index=data.index, columns=data.columns)\n",
    "\n",
    "series = create_windows(data_scaled)\n",
    "\n",
    "X = series[:, :, :100]\n",
    "X = inject_random_nans(X)\n",
    "X = np.nan_to_num(X, nan=0.0)  # reemplazar nan por 0\n",
    "\n",
    "Y = series[:, :, 100:]\n",
    "\n",
    "print(\"Datos preparados:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c159bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Asumimos que tienes: \n",
    "# X â†’ (3000, 9, 100), Y â†’ (3000, 9, 1)\n",
    "\n",
    "# Transponer para que sea (batch, time, features)\n",
    "X_tf = np.transpose(X, (0, 2, 1))  # (3000, 100, 9)\n",
    "Y_tf = Y.squeeze(-1)  # (3000, 9)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_tf, Y_tf, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e16fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def transformer(inputs, head_sz=64, num_heads=3, ff_dim=128, dropout=0.1):\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_sz)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    x_ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    x_ff = layers.Dense(inputs.shape[-1])(x_ff)\n",
    "    x = layers.Dropout(dropout)(x_ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + x_ff)\n",
    "    return x\n",
    "\n",
    "def build_model(input_shape, num_layers=3, num_heads=3, ff_dim=128):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer(x, num_heads=num_heads, ff_dim=ff_dim)\n",
    "\n",
    "    x = layers.Lambda(lambda x: x[:, -1, :])(x)\n",
    "    outputs = layers.Dense(9)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b12f6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 17s 215ms/step - loss: 0.1183 - mse: 0.1183 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 13s 211ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 13s 212ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 13s 214ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 13s 213ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 13s 213ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 13s 216ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 13s 216ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 13s 215ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 13s 216ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 13s 216ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 13s 216ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 13s 220ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 13s 217ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0019 - val_mse: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x768e5c5cc7f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(input_shape=(100, 9), num_layers=4, num_heads=5)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c89d0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en test: 0.001758\n"
     ]
    }
   ],
   "source": [
    "loss, mse = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(f\"MSE en test: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6670248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss predictor trivial: 0.004415\n",
      "Loss transformer entrenado: 0.001758\n"
     ]
    }
   ],
   "source": [
    "baseline_pred = X_test[:, -1, :]\n",
    "baseline_loss = tf.reduce_mean(tf.square(baseline_pred - Y_test)).numpy()\n",
    "\n",
    "print(f\"Loss predictor trivial: {baseline_loss:.6f}\")\n",
    "print(f\"Loss transformer entrenado: {loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
