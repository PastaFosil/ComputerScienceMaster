{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cb515d",
   "metadata": {},
   "source": [
    "# Juan Carlos Perez Ramirez\n",
    "## Procesamiento de Lenguaje Natural\n",
    "## Proyecto final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436549f5",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebebfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 09:29:41.373528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-27 09:29:41.373786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-27 09:29:41.469712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-27 09:29:41.635307: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-27 09:29:42.707677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from scrn import SCRNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8eed9d",
   "metadata": {},
   "source": [
    "### Carga del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29695399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SCRNModel(\n",
       "  (embedding): Embedding(48, 64)\n",
       "  (rnn_cell): SCRNCell(\n",
       "    (linear): Linear(in_features=168, out_features=64, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"vocab.pkl\", \"rb\") as f:\n",
    "    char2idx = pickle.load(f)\n",
    "idx2char = {idx: ch for ch, idx in char2idx.items()}\n",
    "\n",
    "vocab_size = len(char2idx)\n",
    "\n",
    "# Crear modelo con mismos parámetros usados al entrenar\n",
    "model = SCRNModel(\n",
    "    vocab_size=vocab_size,\n",
    "    input_size=64,\n",
    "    hidden_size=64,\n",
    "    context_size=40,\n",
    "    alpha=0.95\n",
    ")\n",
    "model.load_state_dict(torch.load(\"scrn_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef91e79",
   "metadata": {},
   "source": [
    "### Generacion de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f1c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, char2idx, idx2char, prompt, length=200, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    input_size = model.embedding.embedding_dim\n",
    "    hidden_size = model.rnn_cell.hidden_size\n",
    "    context_size = model.rnn_cell.context_size\n",
    "\n",
    "    # Estado inicial\n",
    "    h_t = torch.zeros(1, hidden_size).to(device)\n",
    "    s_t = torch.zeros(1, context_size).to(device)\n",
    "\n",
    "    # Codifica prompt\n",
    "    generated = list(prompt)\n",
    "    input_seq = [char2idx[c] for c in prompt if c in char2idx]\n",
    "    \n",
    "    for idx in input_seq[:-1]:\n",
    "        x = torch.tensor([[idx]]).to(device)\n",
    "        embedded = model.embedding(x).squeeze(1)  # (1, input_size)\n",
    "        h_t, (h_t, s_t) = model.rnn_cell(embedded, (h_t, s_t))\n",
    "\n",
    "    current_idx = input_seq[-1] if input_seq else torch.randint(0, vocab_size, (1,)).item()\n",
    "\n",
    "    for _ in range(length):\n",
    "        x = torch.tensor([[current_idx]]).to(device)\n",
    "        embedded = model.embedding(x).squeeze(1)\n",
    "        h_t, (h_t, s_t) = model.rnn_cell(embedded, (h_t, s_t))\n",
    "        logits = model.fc(h_t)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        # Elegir el siguiente carácter (puedes usar sample o argmax)\n",
    "        current_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(idx2char[current_idx])\n",
    "\n",
    "    return \"\".join(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920372ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the meaning of life is $ n million manume a sharet dust been mond welderal obor and dexoposs <unk> bes \n",
      " to manur havel \n",
      " the clief \n",
      " fundle curroductures are n n n n to of some of that these 's sendcy davled that new to ferning \n",
      " sist \n",
      " all controm \n",
      " fram ewrsicy report econditblas seell \n",
      " ther n <unk> eq said but \n",
      " whi\n"
     ]
    }
   ],
   "source": [
    "prompt = \"the meaning of life is\"\n",
    "output = generate_text(model, char2idx, idx2char, prompt, length=300)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca952652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first day of the week <unk> \n",
      " geargh many the concerdor researge said that equiriss of <unk> as <unk> in new n n $ n freacaust was sidead \n",
      " manage ary tust <unk> <unk> custs onled at most time the some \n",
      " the kny echan pendan \n",
      " but the aboulasinespite including weoks about into defell degulatures devely dochanged <unk> b\n"
     ]
    }
   ],
   "source": [
    "prompt = \"the first day of the week\"\n",
    "output = generate_text(model, char2idx, idx2char, prompt, length=300)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feeb82e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after many days of travely <unk> to that it company because on <unk> some shil what sovity polen \n",
      " the than taker part \n",
      " the polity bone \n",
      " a conton <unk> addinated <unk> <unk> said <unk> <unk> counting win hong <unk> <unk> yestons drupereatment doplow for neldon the fill \n",
      " the have considents and in a <unk> \n",
      " the recited fa\n"
     ]
    }
   ],
   "source": [
    "prompt = \"after many days of travel\"\n",
    "output = generate_text(model, char2idx, idx2char, prompt, length=300)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f464742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is generally believed that using a strong nonlinearity is necessary to capture complexo so. he be a <unk> fordafs \n",
      " the dival funds land instill that alsomerly desponsay yith. naym \n",
      " japach concrucing this some to said would day a call mexue \n",
      " to corpanage sell bliddat to will long that worced \n",
      " gond law less which sersiday that is a franting scomicial azal decaled lound \n",
      " subjecttic\n"
     ]
    }
   ],
   "source": [
    "prompt = \"It is generally believed that using a strong nonlinearity is necessary to capture complex\"\n",
    "output = generate_text(model, char2idx, idx2char, prompt, length=300)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b3264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
